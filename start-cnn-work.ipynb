{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefb8a5d-aa96-4727-9c40-ce90a0b15fb5",
   "metadata": {},
   "source": [
    "# RESTART CNN LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a9bb889-5ee1-4982-9e75-06aa1a44bf1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:16:21.888585Z",
     "iopub.status.busy": "2025-08-22T21:16:21.888391Z",
     "iopub.status.idle": "2025-08-22T21:16:28.769422Z",
     "shell.execute_reply": "2025-08-22T21:16:28.768529Z",
     "shell.execute_reply.started": "2025-08-22T21:16:21.888569Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 14:16:23.396475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, TextVectorization\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25e34d7-a497-4b19-87e0-7e4946fd2c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:16:28.770980Z",
     "iopub.status.busy": "2025-08-22T21:16:28.770381Z",
     "iopub.status.idle": "2025-08-22T21:16:28.775264Z",
     "shell.execute_reply": "2025-08-22T21:16:28.774321Z",
     "shell.execute_reply.started": "2025-08-22T21:16:28.770963Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.getcwd(), \"dataset\")\n",
    "training_data_file = os.path.join(dataset_dir, \"articles-validation-bypublisher-20181122-html-escaped.xml\")\n",
    "target_data_file = os.path.join(dataset_dir, \"ground-truth-validation-bypublisher-20181122.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54d18be-c2d3-4475-b573-050ee35f7790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:16:28.776479Z",
     "iopub.status.busy": "2025-08-22T21:16:28.776154Z",
     "iopub.status.idle": "2025-08-22T21:16:54.924721Z",
     "shell.execute_reply": "2025-08-22T21:16:54.923999Z",
     "shell.execute_reply.started": "2025-08-22T21:16:28.776461Z"
    }
   },
   "outputs": [],
   "source": [
    "datadf = pd.read_xml(path_or_buffer = training_data_file)\n",
    "targetdf = pd.read_xml(path_or_buffer = target_data_file)\n",
    "df = pd.concat([datadf, targetdf], axis = 1)\n",
    "df.columns = [\n",
    "    'id',\n",
    "    'published-at',\n",
    "    'title',\n",
    "    'article',\n",
    "    'id2',\n",
    "    'hyperpartisan',\n",
    "    'bias',\n",
    "    'url',\n",
    "    'labeled-by'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dfc3d1-8505-45cf-aa09-73609ed8fff6",
   "metadata": {},
   "source": [
    "- 80/20 test/train split before fitting tokenizer\n",
    "- tensorflow.keras.preprocessing.text.Tokenizer is deprecated and is not recommended for new code. Exploring [tf.keras.layers.TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72c9b9f-b873-4612-9e0a-a3f3da300348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:16:54.927076Z",
     "iopub.status.busy": "2025-08-22T21:16:54.926939Z",
     "iopub.status.idle": "2025-08-22T21:16:54.980883Z",
     "shell.execute_reply": "2025-08-22T21:16:54.980134Z",
     "shell.execute_reply.started": "2025-08-22T21:16:54.927064Z"
    }
   },
   "outputs": [],
   "source": [
    "bias_mapping = {'left': 0, 'left-center': 1, 'least': 2, 'right-center': 3, 'right': 4 }\n",
    "bias_mapping_reverse = dict((v,k) for k,v in bias_mapping.items())\n",
    "df['bias'] = df['bias'].map(bias_mapping)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['article'], df['bias'], test_size=0.2, random_state=42, stratify = df['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90154fd1-8ceb-4a79-9c83-c7dcc254a59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:07:48.537826Z",
     "iopub.status.busy": "2025-08-22T20:07:48.537599Z",
     "iopub.status.idle": "2025-08-22T20:07:48.542022Z",
     "shell.execute_reply": "2025-08-22T20:07:48.541300Z",
     "shell.execute_reply.started": "2025-08-22T20:07:48.537813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000,)\n",
      "(30000,)\n",
      "(120000,)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6d391-3861-4c8f-bc57-882def3b05b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T19:29:59.456435Z",
     "iopub.status.busy": "2025-08-22T19:29:59.456165Z",
     "iopub.status.idle": "2025-08-22T19:33:41.226512Z",
     "shell.execute_reply": "2025-08-22T19:33:41.225453Z",
     "shell.execute_reply.started": "2025-08-22T19:29:59.456418Z"
    }
   },
   "source": [
    "#### DEPRECATED\n",
    "```python\n",
    "tokenizer = Tokenizer(num_words = 1000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae3161-e67e-4622-86e0-a979edb549d4",
   "metadata": {},
   "source": [
    "#### TextVectorization\n",
    " - output_mode = `int` since the order of words in the text changes their context. Will use an Embedding layer for blah de blah.. why is the embedding layer important here? What does it do????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de51b7f2-3080-46e1-bd95-9cfe71a64d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:01.805843Z",
     "iopub.status.busy": "2025-08-22T21:17:01.805576Z",
     "iopub.status.idle": "2025-08-22T21:17:01.813195Z",
     "shell.execute_reply": "2025-08-22T21:17:01.812351Z",
     "shell.execute_reply.started": "2025-08-22T21:17:01.805828Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "TRAIN_SET_SIZE = 60000\n",
    "\n",
    "int_vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29fca0c-137c-49c6-85bb-6200bdb12773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:03.010728Z",
     "iopub.status.busy": "2025-08-22T21:17:03.010446Z",
     "iopub.status.idle": "2025-08-22T21:17:26.280716Z",
     "shell.execute_reply": "2025-08-22T21:17:26.279296Z",
     "shell.execute_reply.started": "2025-08-22T21:17:03.010714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hits OOM error with set size = 120000\n",
    "# Solution is to stream the records using a TFRecordDataset as described here https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "# However, I'll reduce the size of the training set instead.\n",
    "int_vectorize_layer.adapt(x_train[:TRAIN_SET_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e93f838d-16ed-43cb-8382-a2fe5e2a9151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T20:47:16.441908Z",
     "iopub.status.busy": "2025-08-22T20:47:16.441605Z",
     "iopub.status.idle": "2025-08-22T20:47:16.460999Z",
     "shell.execute_reply": "2025-08-22T20:47:16.460311Z",
     "shell.execute_reply.started": "2025-08-22T20:47:16.441894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  43    1    1    1  399    1  662    1 1092    9    3    1 1116    5\n",
      "   113 1861    1    8   23   48    1    7    1    1    6 1849    1   75\n",
      "     2  813  196   28    1    7    3    1    1    1    1    5    1    6\n",
      "     1    1    1    1    1    1  399    1    1    2    1  364    5    1\n",
      "     9    1    1   46   36  153    4 1487   38    1   37  399    1  261\n",
      "    67    1    1   76 1614    1   17    1   14 1910 1126   30  311   24\n",
      "   656 1276  585    1  829    7  334    6    1    3    1    1  974   79\n",
      "    18    1   92  247  130   26   24  399    6   77   24  399    1   24\n",
      "   714   45    5    2    1 1505    7    2  343    5   68    1    1   17\n",
      "     3    1    6   24  205  860   63  188    9    3    1    5    1 1632\n",
      "     4    2  182    1  393    9   82    3    1    1    5    1  616    1\n",
      "  1629    1    6    1    1   10    2    1 1451    6   12    1   51    9\n",
      "    55  111  705   38    1  343   76    1    1    1    9    2    1    1\n",
      "  1213    5  113  343    6 1184   45 1478    5   30    1   24   17  856\n",
      "     3    1 1980   24 1580    1    2    1   57  112   12    7    1    1\n",
      "    24   17    2  356    5  244  352   31  485 1682    7    3    1    1\n",
      "     1    1    6    1   37    1    1    1    6    1    4  286   71    5\n",
      "     2   96   78   62    2  563   17    1   14   41    1    1  993   42\n",
      "    94    2 1552    5    1  311  104   15    3  163  304  310   10  617\n",
      "    26   67 1148    2 1005  513    1    1   12   23    4   15    1    6\n",
      "     1   76    1    8    1    1   13    3  356   37    1    1 1252    6\n",
      "  1910   22    2   87   24   17 1682  368   24   17  824   71    1  579\n",
      "     1   30 1230  712    5    1    6    1   26   24   65   17    1 1331\n",
      "     7   92  309    1 1126   30    1 1649  149    3  261   25   51   21\n",
      "     1    1    1    1   30  398   17 1127   60    5   35  351   24   58\n",
      "     4  178    4  160 1253    1   11    2  113    1    7    2  424    1\n",
      "  1035   17   67    1   10  617   12 1180 1002    5    1    1    6    1\n",
      "   190    7    6  190   60    7    2 1644    5   35   87  280    2    1\n",
      "     1  175  303    1    1   43  554    8    2    1   52    1   60    5\n",
      "    35    1    7    1  513 1247 1631   26   12    9    1    1   77   12\n",
      "     1   29   52    1    6    1    1   22   35  351   14   67 1973    6\n",
      "    67  312    4  176    1    1 1369    1   58    1    1    7    1  746\n",
      "     1  152    2  424    1    6   24  306    1    6 1422   30  398  429\n",
      "     2 1842    1    4    1    7    1   10  103  673    1 1575    1    5\n",
      "   764 1011    7    1    1    3    1  117    1   58   48    1   19    2\n",
      "     1    1    6    2   88    1    1  331    1    4]]\n"
     ]
    }
   ],
   "source": [
    "print(int_vectorize_layer(x_train.iloc[[0]]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4b81e-1082-4f2d-8c0e-a223561fa53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c18ae7b-5ffa-44ae-ab1a-28c757551184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:37.470550Z",
     "iopub.status.busy": "2025-08-22T21:17:37.470284Z",
     "iopub.status.idle": "2025-08-22T21:17:37.521314Z",
     "shell.execute_reply": "2025-08-22T21:17:37.520245Z",
     "shell.execute_reply.started": "2025-08-22T21:17:37.470533Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(VOCAB_SIZE, MAX_SEQUENCE_LENGTH),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e80b237-b434-42a8-9ed9-496481954883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:38.162798Z",
     "iopub.status.busy": "2025-08-22T21:17:38.162546Z",
     "iopub.status.idle": "2025-08-22T21:17:52.277414Z",
     "shell.execute_reply": "2025-08-22T21:17:52.276666Z",
     "shell.execute_reply.started": "2025-08-22T21:17:38.162784Z"
    }
   },
   "outputs": [],
   "source": [
    "v_train = int_vectorize_layer(x_train[:TRAIN_SET_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea2de11-4757-4c1b-ae29-6131cd74d347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:52.293061Z",
     "iopub.status.busy": "2025-08-22T21:17:52.292857Z",
     "iopub.status.idle": "2025-08-22T21:17:52.307021Z",
     "shell.execute_reply": "2025-08-22T21:17:52.305843Z",
     "shell.execute_reply.started": "2025-08-22T21:17:52.293036Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.fit(v_train, y_train[:1000], batch_size=32, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea2161e-51be-4fe4-8700-d9d562babf49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:52.308133Z",
     "iopub.status.busy": "2025-08-22T21:17:52.307896Z",
     "iopub.status.idle": "2025-08-22T21:24:00.518862Z",
     "shell.execute_reply": "2025-08-22T21:24:00.517974Z",
     "shell.execute_reply.started": "2025-08-22T21:17:52.308114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 14:17:54.788022: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f7724159480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-08-22 14:17:54.788063: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA RTX A2000, Compute Capability 8.6\n",
      "2025-08-22 14:17:54.812942: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-08-22 14:17:54.939619: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91200\n",
      "2025-08-22 14:17:55.029313: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-22 14:17:55.029423: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-08-22 14:17:55.698739: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_575', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2025-08-22 14:17:55.804852: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_842', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   2/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 73ms/step - accuracy: 0.2188 - loss: 1.6051 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755897480.277848   23127 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 34ms/step - accuracy: 0.7574 - loss: 0.6320 - val_accuracy: 0.8538 - val_loss: 0.3965\n",
      "Epoch 2/7\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - accuracy: 0.8943 - loss: 0.3138 - val_accuracy: 0.8634 - val_loss: 0.3818\n",
      "Epoch 3/7\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 35ms/step - accuracy: 0.9450 - loss: 0.1631 - val_accuracy: 0.8671 - val_loss: 0.4237\n",
      "Epoch 4/7\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 34ms/step - accuracy: 0.9685 - loss: 0.0938 - val_accuracy: 0.8699 - val_loss: 0.5096\n",
      "Epoch 5/7\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 36ms/step - accuracy: 0.9762 - loss: 0.0704 - val_accuracy: 0.8713 - val_loss: 0.5492\n",
      "Epoch 6/7\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 34ms/step - accuracy: 0.9818 - loss: 0.0570 - val_accuracy: 0.8668 - val_loss: 0.6324\n",
      "Epoch 7/7\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 35ms/step - accuracy: 0.9822 - loss: 0.0535 - val_accuracy: 0.8647 - val_loss: 0.5995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7968050bf0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TBD: plot the curve and comment on the point at which the validation loss starts increasing.\n",
    "# TBD: save the best model, and retreive it!\n",
    "\n",
    "v_train_y = tf.keras.utils.to_categorical(y_train[:TRAIN_SET_SIZE])\n",
    "model.fit(v_train, v_train_y, batch_size=32, epochs=7, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44163e92-b01c-4c62-9b2d-86ef08e06dab",
   "metadata": {},
   "source": [
    "# END CNN LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be2f5f8-4670-436c-9434-50259018d503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T19:27:49.999129Z",
     "iopub.status.busy": "2025-08-22T19:27:49.998908Z",
     "iopub.status.idle": "2025-08-22T19:27:52.123896Z",
     "shell.execute_reply": "2025-08-22T19:27:52.123255Z",
     "shell.execute_reply.started": "2025-08-22T19:27:49.999114Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00bd32e9-ad19-4295-9545-b229e30c030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df already loaded.. not loading again\n",
      "bag_of_words_df already loaded.. not loading again\n"
     ]
    }
   ],
   "source": [
    "if 'df' not in locals() and 'df' not in globals():\n",
    "    df = pd.read_pickle(os.path.join(os.getcwd(), \"dataset\", \"articles_dataframe.pkl\"))\n",
    "else:\n",
    "    print(\"df already loaded.. not loading again\")\n",
    "\n",
    "if 'bag_of_words_df' not in locals() and 'bag_of_words_df' not in globals():\n",
    "    bag_of_words_df = pd.read_pickle(os.path.join(os.getcwd(), \"dataset\", \"articles_tfidf_vectorized.pkl\"))\n",
    "else:\n",
    "    print(\"bag_of_words_df already loaded.. not loading again\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(bag_of_words_df,\n",
    "                                                df['bias'],\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=42,\n",
    "                                                stratify=df['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f031342-7a49-4113-bd6d-d38ab4248ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 18:11:54.010846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7aa01d0-ff1a-4e8e-ad91-a71afa6ea5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51a65a59-c079-4c3c-9b27-32d11f9a53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 100),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b93c5-b4a6-44c3-b65a-b56c6308453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0949459-e48b-4505-b54e-1c6939c00b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9ms/step - accuracy: 0.1575 - loss: -16494510080.0000 - val_accuracy: 0.1522 - val_loss: -73888587776.0000\n",
      "Epoch 2/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.1576 - loss: -306588188672.0000 - val_accuracy: 0.1522 - val_loss: -684273041408.0000\n",
      "Epoch 3/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 9ms/step - accuracy: 0.1576 - loss: -1422149550080.0000 - val_accuracy: 0.1522 - val_loss: -2440861581312.0000\n",
      "Epoch 4/5\n",
      "\u001b[1m  77/3000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.1565 - loss: -2469632409600.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10a274f8-5754-4c94-961b-181ccdfacfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.4749\n",
      "Test Accuracy: 0.8887\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ae984b-9e4a-4444-b9b2-39dd91dd90d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f5cf220-f166-476e-8978-aeb07a5f567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    1,   14,   22,   16,\n",
       "         43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,\n",
       "        173,   36,  256,    5,   25,  100,   43,  838,  112,   50,  670,\n",
       "          2,    9,   35,  480,  284,    5,  150,    4,  172,  112,  167,\n",
       "          2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
       "         13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,\n",
       "         22,    4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,\n",
       "         43,  530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,\n",
       "         17,   12,   16,  626,   18,    2,    5,   62,  386,   12,    8,\n",
       "        316,    8,  106,    5,    4, 2223, 5244,   16,  480,   66, 3785,\n",
       "         33,    4,  130,   12,   16,   38,  619,    5,   25,  124,   51,\n",
       "         36,  135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,\n",
       "         77,   52,    5,   14,  407,   16,   82,    2,    8,    4,  107,\n",
       "        117, 5952,   15,  256,    4,    2,    7, 3766,    5,  723,   36,\n",
       "         71,   43,  530,  476,   26,  400,  317,   46,    7,    4,    2,\n",
       "       1029,   13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,\n",
       "         56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,   21,\n",
       "        134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,   36,\n",
       "         28,  224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,\n",
       "         88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
       "         16, 5345,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe6b7e-7560-49df-9322-b8d84b3a79a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
