{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefb8a5d-aa96-4727-9c40-ce90a0b15fb5",
   "metadata": {},
   "source": [
    "# RESTART CNN LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a9bb889-5ee1-4982-9e75-06aa1a44bf1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T22:10:17.220106Z",
     "iopub.status.busy": "2025-08-24T22:10:17.219869Z",
     "iopub.status.idle": "2025-08-24T22:10:21.709384Z",
     "shell.execute_reply": "2025-08-24T22:10:21.708566Z",
     "shell.execute_reply.started": "2025-08-24T22:10:17.220091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 15:10:18.656519: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, TextVectorization\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54d18be-c2d3-4475-b573-050ee35f7790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T22:12:55.089895Z",
     "iopub.status.busy": "2025-08-24T22:12:55.089661Z",
     "iopub.status.idle": "2025-08-24T22:12:55.378007Z",
     "shell.execute_reply": "2025-08-24T22:12:55.377303Z",
     "shell.execute_reply.started": "2025-08-24T22:12:55.089882Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_file_path(fname):\n",
    "    return os.path.join(os.path.join(os.getcwd(), \"dataset\", fname))\n",
    "\n",
    "df = pd.read_pickle(dataset_file_path(\"articles_dataframe.pkl\"))\n",
    "\n",
    "bias_mapping = {'left': 0, 'left-center': 1, 'least': 2, 'right-center': 3, 'right': 4 }\n",
    "bias_mapping_reverse = dict((v,k) for k,v in bias_mapping.items())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['article'], df['bias'], test_size=0.2, random_state=42, stratify = df['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dfc3d1-8505-45cf-aa09-73609ed8fff6",
   "metadata": {},
   "source": [
    "- 80/20 test/train split before fitting tokenizer\n",
    "- tensorflow.keras.preprocessing.text.Tokenizer is deprecated and is not recommended for new code. Exploring [tf.keras.layers.TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90154fd1-8ceb-4a79-9c83-c7dcc254a59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T22:20:37.492703Z",
     "iopub.status.busy": "2025-08-24T22:20:37.492446Z",
     "iopub.status.idle": "2025-08-24T22:20:37.496753Z",
     "shell.execute_reply": "2025-08-24T22:20:37.495866Z",
     "shell.execute_reply.started": "2025-08-24T22:20:37.492688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(15000,)\n",
      "(60000,)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "682c14c4-b01f-4daf-92aa-c61bf4afdd2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T22:22:50.194708Z",
     "iopub.status.busy": "2025-08-24T22:22:50.194466Z",
     "iopub.status.idle": "2025-08-24T22:22:50.207268Z",
     "shell.execute_reply": "2025-08-24T22:22:50.206530Z",
     "shell.execute_reply.started": "2025-08-24T22:22:50.194694Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://adriangb.com/scikeras/stable/migration.html#why-switch-to-scikeras\n",
    "# requires `pip install scikeras`\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bac6af8f-1148-4376-ab2e-8947f176a594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T23:09:03.591201Z",
     "iopub.status.busy": "2025-08-24T23:09:03.590950Z",
     "iopub.status.idle": "2025-08-24T23:09:03.595682Z",
     "shell.execute_reply": "2025-08-24T23:09:03.594915Z",
     "shell.execute_reply.started": "2025-08-24T23:09:03.591186Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(5000, 1000))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64,activation='relu',kernel_initializer=kernel_initializer))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "994ecf4b-85fc-47bb-97bc-deaa77cd2fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T23:10:00.108886Z",
     "iopub.status.busy": "2025-08-24T23:10:00.108573Z",
     "iopub.status.idle": "2025-08-24T23:10:00.112801Z",
     "shell.execute_reply": "2025-08-24T23:10:00.111883Z",
     "shell.execute_reply.started": "2025-08-24T23:10:00.108871Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = KerasClassifier(build_fn=create_model,verbose=3, dropout=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb28506e-49ac-4e86-aa4e-9218881ff7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T23:10:01.371258Z",
     "iopub.status.busy": "2025-08-24T23:10:01.371029Z",
     "iopub.status.idle": "2025-08-24T23:10:25.461198Z",
     "shell.execute_reply": "2025-08-24T23:10:25.460362Z",
     "shell.execute_reply.started": "2025-08-24T23:10:01.371245Z"
    }
   },
   "outputs": [],
   "source": [
    "int_vectorize_layer = TextVectorization(\n",
    "    max_tokens=5000,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=200)\n",
    "\n",
    "int_vectorize_layer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6b9e5f4-67ae-49f4-b0d0-ed8050aa5c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T23:10:26.466058Z",
     "iopub.status.busy": "2025-08-24T23:10:26.465759Z",
     "iopub.status.idle": "2025-08-24T23:10:42.116839Z",
     "shell.execute_reply": "2025-08-24T23:10:42.116099Z",
     "shell.execute_reply.started": "2025-08-24T23:10:26.466044Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_vec = int_vectorize_layer(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe82aea0-3e3c-4964-bbca-c05e30fdafde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T23:12:38.206487Z",
     "iopub.status.busy": "2025-08-24T23:12:38.206258Z",
     "iopub.status.idle": "2025-08-24T23:12:38.211532Z",
     "shell.execute_reply": "2025-08-24T23:12:38.210739Z",
     "shell.execute_reply.started": "2025-08-24T23:12:38.206474Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_tf = tf.keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79b09f33-5cc9-459f-8743-a3e6c8427b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T23:10:43.821202Z",
     "iopub.status.busy": "2025-08-24T23:10:43.820896Z",
     "iopub.status.idle": "2025-08-24T23:10:43.824655Z",
     "shell.execute_reply": "2025-08-24T23:10:43.823942Z",
     "shell.execute_reply.started": "2025-08-24T23:10:43.821188Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'dropout': [0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e717a2d6-c2e2-45c5-a969-8cd98bb7255c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T23:12:43.604223Z",
     "iopub.status.busy": "2025-08-24T23:12:43.603991Z",
     "iopub.status.idle": "2025-08-24T23:12:43.806134Z",
     "shell.execute_reply": "2025-08-24T23:12:43.804403Z",
     "shell.execute_reply.started": "2025-08-24T23:12:43.604209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([12000, 12001, 12002, ..., 59997, 59998, 59999])",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[32m      3\u001b[39m cv_grid = GridSearchCV(\n\u001b[32m      4\u001b[39m     clf,\n\u001b[32m      5\u001b[39m     param_grid = param_grid,\n\u001b[32m      6\u001b[39m     scoring = \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     verbose = \u001b[32m3\u001b[39m,\n\u001b[32m      8\u001b[39m     n_jobs = \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mcv_grid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:851\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    847\u001b[39m     estimator = estimator.set_params(**clone(parameters, safe=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    849\u001b[39m start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m X_train, y_train = \u001b[43m_safe_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    852\u001b[39m X_test, y_test = _safe_split(estimator, X, y, test, train)\n\u001b[32m    854\u001b[39m result = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/utils/metaestimators.py:156\u001b[39m, in \u001b[36m_safe_split\u001b[39m\u001b[34m(estimator, X, y, indices, train_indices)\u001b[39m\n\u001b[32m    154\u001b[39m         X_subset = X[np.ix_(indices, train_indices)]\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     X_subset = \u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    159\u001b[39m     y_subset = _safe_indexing(y, indices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/utils/_indexing.py:349\u001b[39m, in \u001b[36m_safe_indexing\u001b[39m\u001b[34m(X, indices, axis)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m warnings.warn(\n\u001b[32m    342\u001b[39m         message=\u001b[33m\"\u001b[39m\u001b[33mA data object with support for the dataframe interchange protocol\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwas passed, but scikit-learn does currently not know how to handle this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mkind of data. Some array/list indexing will be tried.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    345\u001b[39m         category=\u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    346\u001b[39m     )\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/sklearn/utils/_indexing.py:40\u001b[39m, in \u001b[36m_array_indexing\u001b[39m\u001b[34m(array, key, key_dtype, axis)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m     39\u001b[39m     key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/lib/python3.12/site-packages/tensorflow/python/ops/tensor_getitem_override.py:62\u001b[39m, in \u001b[36m_check_index\u001b[39m\u001b[34m(idx)\u001b[39m\n\u001b[32m     57\u001b[39m dtype = \u001b[38;5;28mgetattr\u001b[39m(idx, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtypes.as_dtype(dtype) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m     59\u001b[39m     idx.shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx.shape) == \u001b[32m1\u001b[39m):\n\u001b[32m     60\u001b[39m   \u001b[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[32m     61\u001b[39m   \u001b[38;5;66;03m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR + \u001b[33m\"\u001b[39m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m\"\u001b[39m.format(idx))\n",
      "\u001b[31mTypeError\u001b[39m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([12000, 12001, 12002, ..., 59997, 59998, 59999])"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv_grid = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid = param_grid,\n",
    "    scoring = \"accuracy\",\n",
    "    verbose = 3,\n",
    "    n_jobs = 1)\n",
    "\n",
    "cv_grid.fit(x_train_vec, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddf24892-2207-4a0c-85e4-7dffe099ac9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T23:07:01.234781Z",
     "iopub.status.busy": "2025-08-24T23:07:01.234545Z",
     "iopub.status.idle": "2025-08-24T23:07:01.239866Z",
     "shell.execute_reply": "2025-08-24T23:07:01.238962Z",
     "shell.execute_reply.started": "2025-08-24T23:07:01.234768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__model', 'estimator__build_fn', 'estimator__warm_start', 'estimator__random_state', 'estimator__optimizer', 'estimator__loss', 'estimator__metrics', 'estimator__batch_size', 'estimator__validation_batch_size', 'estimator__verbose', 'estimator__callbacks', 'estimator__validation_split', 'estimator__shuffle', 'estimator__run_eagerly', 'estimator__epochs', 'estimator__class_weight', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_grid.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae3161-e67e-4622-86e0-a979edb549d4",
   "metadata": {},
   "source": [
    "#### TextVectorization\n",
    " - output_mode = `int` since the order of words in the text changes their context. Will use an Embedding layer for blah de blah.. why is the embedding layer important here? What does it do????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de51b7f2-3080-46e1-bd95-9cfe71a64d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:01.805843Z",
     "iopub.status.busy": "2025-08-22T21:17:01.805576Z",
     "iopub.status.idle": "2025-08-22T21:17:01.813195Z",
     "shell.execute_reply": "2025-08-22T21:17:01.812351Z",
     "shell.execute_reply.started": "2025-08-22T21:17:01.805828Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "TRAIN_SET_SIZE = 60000\n",
    "\n",
    "int_vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29fca0c-137c-49c6-85bb-6200bdb12773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:03.010728Z",
     "iopub.status.busy": "2025-08-22T21:17:03.010446Z",
     "iopub.status.idle": "2025-08-22T21:17:26.280716Z",
     "shell.execute_reply": "2025-08-22T21:17:26.279296Z",
     "shell.execute_reply.started": "2025-08-22T21:17:03.010714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hits OOM error with set size = 120000\n",
    "# Solution is to stream the records using a TFRecordDataset as described here https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "# However, I'll reduce the size of the training set instead.\n",
    "int_vectorize_layer.adapt(x_train[:TRAIN_SET_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f838d-16ed-43cb-8382-a2fe5e2a9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int_vectorize_layer(x_train.iloc[[0]]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4b81e-1082-4f2d-8c0e-a223561fa53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c18ae7b-5ffa-44ae-ab1a-28c757551184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:37.470550Z",
     "iopub.status.busy": "2025-08-22T21:17:37.470284Z",
     "iopub.status.idle": "2025-08-22T21:17:37.521314Z",
     "shell.execute_reply": "2025-08-22T21:17:37.520245Z",
     "shell.execute_reply.started": "2025-08-22T21:17:37.470533Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(VOCAB_SIZE, MAX_SEQUENCE_LENGTH),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80b237-b434-42a8-9ed9-496481954883",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_train = int_vectorize_layer(x_train[:TRAIN_SET_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea2de11-4757-4c1b-ae29-6131cd74d347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T21:17:52.293061Z",
     "iopub.status.busy": "2025-08-22T21:17:52.292857Z",
     "iopub.status.idle": "2025-08-22T21:17:52.307021Z",
     "shell.execute_reply": "2025-08-22T21:17:52.305843Z",
     "shell.execute_reply.started": "2025-08-22T21:17:52.293036Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.fit(v_train, y_train[:1000], batch_size=32, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2161e-51be-4fe4-8700-d9d562babf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD: plot the curve and comment on the point at which the validation loss starts increasing.\n",
    "# TBD: save the best model, and retreive it!\n",
    "\n",
    "v_train_y = tf.keras.utils.to_categorical(y_train[:TRAIN_SET_SIZE])\n",
    "model.fit(v_train, v_train_y, batch_size=32, epochs=7, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
