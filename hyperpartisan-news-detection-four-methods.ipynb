{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9779f85a-7463-481a-8527-155cfea82cd9",
   "metadata": {},
   "source": [
    "# CS450.4 Final Project - adhavle - Classifying Partisan Bias in News Articles\n",
    "- I am attempting to replicate some of the methods used in [Classifying Partisan Bias in News Articles:\n",
    " Leveraging an Understanding of Political Language\n",
    " and Article Structure](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1234/final-reports/final-report-169502805.pdf), which uses a dataset from a competition on detecting hyperpartisan and fake news.\n",
    "- Dataset location [Data for PAN at SemEval 2019 Task 4: Hyperpartisan News Detection](https://zenodo.org/records/1489920)\n",
    "- Also see [Hyperpartisan News Detection 2019](https://pan.webis.de/semeval19/semeval19-web/#data) and [SemEval-2019 Task 4: Hyperpartisan News Detection](https://aclanthology.org/S19-2145.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0dde696-9068-4bd5-bba2-cfeff7051bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ce9678-537d-477e-be0f-8a0a77a5ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data locations\n",
    "dataset_dir = os.path.join(os.getcwd(), \"dataset\")\n",
    "training_data_file = os.path.join(dataset_dir, \"articles-validation-bypublisher-20181122-html-escaped.xml\")\n",
    "target_data_file = os.path.join(dataset_dir, \"ground-truth-validation-bypublisher-20181122.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6b8a92-3b88-43d2-b34c-09fb3b772671",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf = pd.read_xml(path_or_buffer = training_data_file)\n",
    "targetdf = pd.read_xml(path_or_buffer = target_data_file)\n",
    "df = pd.concat([datadf, targetdf], axis = 1)\n",
    "df.columns = ['id', 'published-at', 'title', 'article', 'id2', 'hyperpartisan', 'bias',\n",
    "       'url', 'labeled-by']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2ed403-2e00-4829-9811-56b5dbcfb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS: dataframe has 150000 records as expected\n",
      "PASS: no null values detected for column 'id'\n",
      "PASS: no null values detected for column 'id2'\n",
      "PASS: no null values detected for column 'article'\n",
      "PASS: no null values detected for column 'bias'\n",
      "PASS: all article IDs from training file and target file matched (id == id2 for all records)\n"
     ]
    }
   ],
   "source": [
    "# run some test cases to ensure the data is good\n",
    "if len(df) == 150_000:\n",
    "    print(f\"PASS: dataframe has {len(df)} records as expected\")\n",
    "else:\n",
    "    print(f\"FAIL: dataframe has {len(df)} records - expected 150,000\")\n",
    "\n",
    "def validate_column_does_not_have_null_values(column_name):\n",
    "    if df[column_name].isnull().sum() == 0:\n",
    "        print(f\"PASS: no null values detected for column '{column_name}'\")\n",
    "    else:\n",
    "        print(f\"FAIL: {df[column_name].isnull().sum()} null values for column '{column_name}' not expected\")\n",
    "\n",
    "validate_column_does_not_have_null_values(\"id\")\n",
    "validate_column_does_not_have_null_values(\"id2\")\n",
    "validate_column_does_not_have_null_values(\"article\")\n",
    "validate_column_does_not_have_null_values(\"bias\")\n",
    "\n",
    "id_matches = df['id'] == df['id2']\n",
    "n_not_matched = id_matches.value_counts().get(False, 0)\n",
    "n_matched = id_matches.value_counts().get(True, 0)\n",
    "if n_matched == 150_000 and n_not_matched == 0:\n",
    "    print(f\"PASS: all article IDs from training file and target file matched (id == id2 for all records)\")\n",
    "else:\n",
    "    print(f\"FAIL: {n_matched} article IDs from training file matched, BUT {n_not_matched} article IDs did not match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd1906-96d3-40d5-b0ad-324a075be408",
   "metadata": {},
   "source": [
    "### Comments\n",
    "The dataset is loaded along with target values. The `id2` column has served its purpose in validating the join with the target data and can be dropped going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f5e2a99-25a3-42a4-945c-812f2a8d6ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             150000 non-null  int64 \n",
      " 1   published-at   100492 non-null  object\n",
      " 2   title          137723 non-null  object\n",
      " 3   article        150000 non-null  object\n",
      " 4   hyperpartisan  150000 non-null  bool  \n",
      " 5   bias           150000 non-null  object\n",
      " 6   url            150000 non-null  object\n",
      " 7   labeled-by     150000 non-null  object\n",
      "dtypes: bool(1), int64(1), object(6)\n",
      "memory usage: 8.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>published-at</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>hyperpartisan</th>\n",
       "      <th>bias</th>\n",
       "      <th>url</th>\n",
       "      <th>labeled-by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>1494825</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;By Andrew Osborn&lt;/p&gt; \\n&lt;p&gt;MOSCOW (Reuters) ...</td>\n",
       "      <td>True</td>\n",
       "      <td>left</td>\n",
       "      <td>http://politicususa.com/2017/10/04/russia-thro...</td>\n",
       "      <td>publisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>1494857</td>\n",
       "      <td>None</td>\n",
       "      <td>I Now Pronounce You Spouse and Spouse</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt; \\n&lt;p&gt;In keeping with its reputation of...</td>\n",
       "      <td>True</td>\n",
       "      <td>right</td>\n",
       "      <td>http://barbwire.com/2014/07/14/now-pronounce-s...</td>\n",
       "      <td>publisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>1494877</td>\n",
       "      <td>2016-03-15</td>\n",
       "      <td>It's now clear that only a Democrat can stop D...</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"\" type=\"internal\"&gt;Donald Trump's&lt;/...</td>\n",
       "      <td>True</td>\n",
       "      <td>left</td>\n",
       "      <td>https://vox.com/2016/3/1/11144320/super-tuesda...</td>\n",
       "      <td>publisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>1494883</td>\n",
       "      <td>2016-02-28</td>\n",
       "      <td>The Liberal Redneck: 'My proudest moment as a ...</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt; \\n&lt;p&gt;LR the Liberal Redneck here, comi...</td>\n",
       "      <td>True</td>\n",
       "      <td>left</td>\n",
       "      <td>http://americannewsx.com/politics/liberal-redn...</td>\n",
       "      <td>publisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>1494893</td>\n",
       "      <td>None</td>\n",
       "      <td>Obama’s Victory: Fourth Global Press Roundup</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt; \\n&lt;p&gt;&lt;/p&gt; \\n&lt;p&gt;From &lt;a href=\"http://ww...</td>\n",
       "      <td>False</td>\n",
       "      <td>least</td>\n",
       "      <td>http://themoderatevoice.com/obamas-victory-fou...</td>\n",
       "      <td>publisher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id published-at  \\\n",
       "149995  1494825         None   \n",
       "149996  1494857         None   \n",
       "149997  1494877   2016-03-15   \n",
       "149998  1494883   2016-02-28   \n",
       "149999  1494893         None   \n",
       "\n",
       "                                                    title  \\\n",
       "149995                                                NaN   \n",
       "149996              I Now Pronounce You Spouse and Spouse   \n",
       "149997  It's now clear that only a Democrat can stop D...   \n",
       "149998  The Liberal Redneck: 'My proudest moment as a ...   \n",
       "149999       Obama’s Victory: Fourth Global Press Roundup   \n",
       "\n",
       "                                                  article  hyperpartisan  \\\n",
       "149995  <p>By Andrew Osborn</p> \\n<p>MOSCOW (Reuters) ...           True   \n",
       "149996  <p></p> \\n<p>In keeping with its reputation of...           True   \n",
       "149997  <p><a href=\"\" type=\"internal\">Donald Trump's</...           True   \n",
       "149998  <p></p> \\n<p>LR the Liberal Redneck here, comi...           True   \n",
       "149999  <p></p> \\n<p></p> \\n<p>From <a href=\"http://ww...          False   \n",
       "\n",
       "         bias                                                url labeled-by  \n",
       "149995   left  http://politicususa.com/2017/10/04/russia-thro...  publisher  \n",
       "149996  right  http://barbwire.com/2014/07/14/now-pronounce-s...  publisher  \n",
       "149997   left  https://vox.com/2016/3/1/11144320/super-tuesda...  publisher  \n",
       "149998   left  http://americannewsx.com/politics/liberal-redn...  publisher  \n",
       "149999  least  http://themoderatevoice.com/obamas-victory-fou...  publisher  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('id2', axis=1)\n",
    "df.info()\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76d98a-7720-4dad-9118-d8a030eb8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english', # see https://aclanthology.org/W18-2502/\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.7)\n",
    "\n",
    "\n",
    "seconds_start_time = time.time() # replace with timer.start, and timer.end methods. \n",
    "\n",
    "bag_of_words = vectorizer.fit_transform(df['article'])\n",
    "\n",
    "print(f\"vectorizer.fit_transform took {time.time() - seconds_start_time} seconds\")\n",
    "\n",
    "bag_of_words_df = pd.DataFrame(\n",
    "    bag_of_words.toarray(), \n",
    "    columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "bag_of_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd288a2-82a7-41e2-9635-6c9280dc6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(bag_of_words_df, \n",
    "                                                    df['bias'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=df['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9969a-6008-4880-a4ac-110af3ab29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter\n",
    "# https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-definitions/52388406#52388406\n",
    "# https://forecastegy.com/posts/how-to-solve-logistic-regression-not-converging-in-scikit-learn/\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "seconds_start_time = time.time() # replace with timer.start, and timer.end methods. \n",
    "model.fit(x_train, y_train)\n",
    "print(f\"model.fit took {time.time() - seconds_start_time} seconds\")\n",
    "\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd548f11-9b28-48af-b363-fe3e72f3eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    p = (model.predict(x_test.iloc[[i]]))[0]\n",
    "    prb = model.predict_proba(x_test.iloc[[i]])\n",
    "    a = ((y_test.iloc[[i]]).values)[0]\n",
    "    matched = \"matched\"\n",
    "    if p != a:\n",
    "        matched = \"NOT MATCHED\"\n",
    "    # print(f\"{i} - {prb} predicted {p} - actual {a} - {matched}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d9699-8eb2-4a7e-9190-f20049a33e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ef3b6-f3a7-46c5-82bb-99b75a001a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_palette = sns.color_palette(\"Paired\")\n",
    "bias_palette = [\n",
    "    base_palette[1], # blue (left)\n",
    "    base_palette[0], # light blue (left-center)\n",
    "    base_palette[8], # purple (least)\n",
    "    base_palette[4], # light red (right-center)\n",
    "    base_palette[5], # red (right)\n",
    "]\n",
    "\n",
    "data_distribution_chart = sns.displot(\n",
    "    data = df,\n",
    "    x = df.index,\n",
    "    hue = \"bias\",\n",
    "    multiple = \"stack\",\n",
    "    height = 3,\n",
    "    aspect = 3,\n",
    "    hue_order = ['left', 'left-center', 'least', 'right-center', 'right'],\n",
    "    palette = bias_palette)\n",
    "\n",
    "data_distribution_chart.set_xlabels(\"article #\")\n",
    "data_distribution_chart.set_ylabels(\"scored bias\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43528010-5ff9-4692-a42b-32bcd624c151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
